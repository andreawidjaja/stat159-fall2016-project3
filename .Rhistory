model1=summary(regsubsets(cnt~.,data=data, nvmax=16))
#Adjusted R-Squared
which.max(model1$adjr2) #Tells us to use 7 variables
#AIC
which.min(model1$bic-((ncol(data)+1)*log(nrow(data))) + (2*(ncol(data)+1))) #6 variables
#BIC
which.min(model1$bic) #6 variables
#Mallow's CP
which.min(model1$cp) #6 variables
cv_mse=function(data, var){
set.seed(0)
mse=vector()
indices=sample(nrow(data))
data=data[indices,]
for(i in 1:10){
m=lm(cnt~., data=data[-c(1:1737 + 1737*(i-1)), var])
y_hat=as.numeric(predict(m, data[c(1:1737 + 1737*(i-1)), ]))
mse[i]=mean((data[c(1:1737 + 1737*(i-1)),"cnt"]-y_hat)^2)
}
return(mean(mse))
}
#comparing mse of recommended variables for each criteria
cv_mse(data, c("season3", "season4", "weathersit2", "atemp", "windspeed", "hum","cnt"))  #23682.54
cv_mse(data, c("season3","season4", "weathersit2", "atemp", "weathersit4", "hum", "windspeed", "cnt")) #23680.92
#With our transformed regression, using 7 variables is the optimal number to use
#######################################
#Creating table to use in report
mse=c(23680.92,28817.16)
df=data.frame(c(mse[1],model1$which[7,-1]), c(mse[2],model$which[6,-1]))
colnames(df)=c("Untransformed Regression", "Transformed Regression")
rownames(df)[1]=c("Mean Squared Error")
save(df, file="/Users/josephfrancia/Desktop/Fall_2016/Stats151a/Takehome/df.RData")
library(shiny)
source("functions.R")
#read in file scaled_data.csv
scaled_data=read.csv("../../data/generated_data/scaled_data.csv")[,-1]
ui <- fluidPage(
actionButton("click", label="Generate Relevant Variables"), #Creating an action button
radioButtons("text", label=h3("Variable Selection Method"), choices=list("Lasso"="Lasso", "BIC"="BIC","P-Value"="P-Value")),
radioButtons("radio", label = h3("Select Graduation Rate of Interest"),
choices = list("Overall Graduation Rate" = "C150_4", "Graduation Rates of White People" = "C150_4_WHITE", "Graduation Rates of Black People" = "C150_4_BLACK",
"Graduation Rates of Hispanic People"="C150_4_HISP", "Graduation Rates of Asian People"="C150_4_ASIAN", "Graduation Rates of Native Americans"="C150_4_AIAN",
"Graduation Rates of Pacific Islanders"="C150_4_NHPI"),
selected = 1),
numericInput("var_num", label=h3("Number of Variables"), value=1:10),
tableOutput("variables")
)
server <- function(input, output){
observeEvent(input$click,{
df=choosing_response(scaled_data, input$radio)
if(input$text=="Lasso"){
output$variables=renderTable({lasso_select(df,input$radio,input$var_num)})
}
else if(input$text=="BIC"){
output$variables=renderTable({bic_select(df,input$radio,input$var_num)})
}
else if(input$text=="P-Value"){
output$variables=renderTable({forward_p(df, input$var_num)})
}
})
}
shinyApp(ui = ui, server = server)
library(shiny)
source("functions.R")
#read in file scaled_data.csv
scaled_data=read.csv("../../data/generated_data/scaled_data.csv")[,-1]
ui <- fluidPage(
actionButton("click", label="Generate Relevant Variables"), #Creating an action button
radioButtons("text", label=h3("Variable Selection Method"), choices=list("Lasso"="Lasso", "BIC"="BIC","P-Value"="P-Value")),
radioButtons("radio", label = h3("Select Graduation Rate of Interest"),
choices = list("Overall Graduation Rate" = "C150_4", "Graduation Rates of White People" = "C150_4_WHITE", "Graduation Rates of Black People" = "C150_4_BLACK",
"Graduation Rates of Hispanic People"="C150_4_HISP", "Graduation Rates of Asian People"="C150_4_ASIAN", "Graduation Rates of Native Americans"="C150_4_AIAN",
"Graduation Rates of Pacific Islanders"="C150_4_NHPI"),
selected = 1),
numericInput("var_num", label=h3("Number of Variables"), value=1:10),
tableOutput("variables")
)
server <- function(input, output){
observeEvent(input$click,{
df=choosing_response(scaled_data, input$radio)
if(input$text=="Lasso"){
output$variables=renderTable({lasso_select(df,input$radio,input$var_num)})
}
else if(input$text=="BIC"){
output$variables=renderTable({bic_select(df,input$radio,input$var_num)})
}
else if(input$text=="P-Value"){
output$variables=renderTable({forward_p(df, input$var_num)})
}
})
}
shinyApp(ui = ui, server = server)
library(shiny)
source("functions.R")
#read in file scaled_data.csv
scaled_data=read.csv("../../data/generated_data/scaled_data.csv")[,-1]
setwd("/Users/josephfrancia/Desktop/Fall_2016/Stats159/stat159-fall2016-project3/code/scripts")
scaled_data=read.csv("data/generated_data/scaled_data.csv")[,-1]
choosing_response=function(dataframe, character){
response=which(colnames(dataframe)==character)
dataframe[,setdiff(93:99, response)]=NULL #getting rid of all graduation rates, except for black graduation rates
dataframe= subset(dataframe, select=c(setdiff(1:ncol(dataframe),response), response))
return(dataframe)
}
lasso_select=function(dataframe, character, n){
set.seed(0)
lasso=cv.glmnet(as.matrix(dataframe[,-which(colnames(dataframe)==character)]), dataframe[,which(colnames(dataframe)==character)])
sparse_vector=glmnet(as.matrix(dataframe[,-which(colnames(dataframe)==character)]), dataframe[,which(colnames(dataframe)==character)], lambda=lasso$lambda.1se)
relevant=which(coef(sparse_vector)!=0)[-1] #Extracting the nonzero values of our beta vector (aka, the relevant variables)... also, i removed the beta coefficient corresponding to the intercept
lasso_var=data.frame(row.names(coef(sparse_vector))[relevant], coef(sparse_vector)[relevant]) #Printing out the names of our relevant variables!
colnames(lasso_var)=c("Relevant_Variables", "Beta_Coefficients")
ordered=order(abs(lasso_var$Beta_Coefficients), decreasing=TRUE)
lasso_var=lasso_var[ordered,]
return(lasso_var[1:n,])
}
bic_select=function(dataframe, character, n){
set.seed(0)
model=summary(regsubsets(as.matrix(dataframe[,-which(colnames(dataframe)==character)]), dataframe[,which(colnames(dataframe)==character)], method="forward", nvmax=15))
bic_var=model$which[which.min(model$bic),]
relevant=which(bic_var==TRUE)[-1]
lm_obj=lm.fit(as.matrix(dataframe[, relevant-1]), dataframe[,which(colnames(dataframe)==character)])
bic_var=data.frame(rownames(data.frame(lm_obj$coefficients)),lm_obj$coefficients)
rownames(bic_var)=NULL
colnames(bic_var)=c("Relevant_Variables","Beta_Coefficients")
ordered=order(abs(bic_var$Beta_Coefficients), decreasing=TRUE)
bic_var=bic_var[ordered,]
return(bic_var[1:n,])
}
#Nick, you can do the forward selection stuff with p-values. you'll have to make a function that does that since there's no built in R thing that does that
forward_p<-function(data,p){
set.seed(0)
#data argumented must formatted such that the last column is the response variable
#p must be the number of predictor variables to use for the model, ie after addidng p variables to our model
#we stop adding predictors to our model, p must be >= 1
#break data into response and predictors,
predictors<-data[,-c(length(colnames(data)))]
response<-data[,length(colnames(data))]
response_name<-colnames(data)[dim(data)[2]]
#resultant list of all models
models<-vector(length=p)
for(i in seq(1:p)) {
temp1<-vector(length=(length(colnames(predictors))))
for (j in seq(1:(length(colnames(predictors))))){
#Initial loop to fill in temp1
if (!models[1]){
#Store t-value of regression of response variable ran on just the j'th feature of predictors
temp1[j]<-summary(lm(paste(response_name,"~."),data=data))$coefficients[i+1,4]
}
else {
#Skip if predictor is already in our model so far
if (j %in% models) {
#assign value of two so that which.min call won't mistake and double count predictors
temp1[j]<-2
next
}
else {
#Store t-value of newly added predictor variable to regression model
temp1[j]<-summary(lm(paste(response_name,"~.",sep=""),data=data[,c((models[models != 0]),j,dim(data)[2])]))$coefficients[i+1,4]
}
}
}
#store the predictor whose t-value is the lowest when added to the model
models[i]<-which.min(temp1)
}
print("hit this")
coefficients<-summary(lm(paste(response_name,"~.",sep=""),data=data[,c(models,dim(data)[2])]))$coefficients
names<-names(coefficients[,2])[1:p+1]
value<-coefficients[1:p+1,2]
info<-data.frame(models,names,value)
return(info)
}
character="C150_4"
dataframe=scaled_data
sample=choosing_response(scaled_data, character)
lasso=lasso_select(sample, character, 5)
colnames(lasso)=c("Lasso Relevant Variables", "Beta Coefficients")
bic=bic_select(sample, character, 5)
colnames(bic)=c("BIC Relevant Variables", "Beta Coefficients")
p_val=forward_p(sample,5)[,c(2,3)]
colnames(p_val)=c("P-Vals Relevant Variables", "Beta Coefficients")
df=cbind(lasso, bic, p_val)
setwd("/Users/josephfrancia/Desktop/Fall_2016/Stats159/stat159-fall2016-project3/code/scripts")
scaled_data=read.csv("data/generated_data/scaled_data.csv")[,-1]
scaled_data=read.csv("../../data/generated_data/scaled_data.csv")[,-1]
choosing_response=function(dataframe, character){
response=which(colnames(dataframe)==character)
dataframe[,setdiff(93:99, response)]=NULL #getting rid of all graduation rates, except for black graduation rates
dataframe= subset(dataframe, select=c(setdiff(1:ncol(dataframe),response), response))
return(dataframe)
}
lasso_select=function(dataframe, character, n){
set.seed(0)
lasso=cv.glmnet(as.matrix(dataframe[,-which(colnames(dataframe)==character)]), dataframe[,which(colnames(dataframe)==character)])
sparse_vector=glmnet(as.matrix(dataframe[,-which(colnames(dataframe)==character)]), dataframe[,which(colnames(dataframe)==character)], lambda=lasso$lambda.1se)
relevant=which(coef(sparse_vector)!=0)[-1] #Extracting the nonzero values of our beta vector (aka, the relevant variables)... also, i removed the beta coefficient corresponding to the intercept
lasso_var=data.frame(row.names(coef(sparse_vector))[relevant], coef(sparse_vector)[relevant]) #Printing out the names of our relevant variables!
colnames(lasso_var)=c("Relevant_Variables", "Beta_Coefficients")
ordered=order(abs(lasso_var$Beta_Coefficients), decreasing=TRUE)
lasso_var=lasso_var[ordered,]
return(lasso_var[1:n,])
}
bic_select=function(dataframe, character, n){
set.seed(0)
model=summary(regsubsets(as.matrix(dataframe[,-which(colnames(dataframe)==character)]), dataframe[,which(colnames(dataframe)==character)], method="forward", nvmax=15))
bic_var=model$which[which.min(model$bic),]
relevant=which(bic_var==TRUE)[-1]
lm_obj=lm.fit(as.matrix(dataframe[, relevant-1]), dataframe[,which(colnames(dataframe)==character)])
bic_var=data.frame(rownames(data.frame(lm_obj$coefficients)),lm_obj$coefficients)
rownames(bic_var)=NULL
colnames(bic_var)=c("Relevant_Variables","Beta_Coefficients")
ordered=order(abs(bic_var$Beta_Coefficients), decreasing=TRUE)
bic_var=bic_var[ordered,]
return(bic_var[1:n,])
}
#Nick, you can do the forward selection stuff with p-values. you'll have to make a function that does that since there's no built in R thing that does that
forward_p<-function(data,p){
set.seed(0)
#data argumented must formatted such that the last column is the response variable
#p must be the number of predictor variables to use for the model, ie after addidng p variables to our model
#we stop adding predictors to our model, p must be >= 1
#break data into response and predictors,
predictors<-data[,-c(length(colnames(data)))]
response<-data[,length(colnames(data))]
response_name<-colnames(data)[dim(data)[2]]
#resultant list of all models
models<-vector(length=p)
for(i in seq(1:p)) {
temp1<-vector(length=(length(colnames(predictors))))
for (j in seq(1:(length(colnames(predictors))))){
#Initial loop to fill in temp1
if (!models[1]){
#Store t-value of regression of response variable ran on just the j'th feature of predictors
temp1[j]<-summary(lm(paste(response_name,"~."),data=data))$coefficients[i+1,4]
}
else {
#Skip if predictor is already in our model so far
if (j %in% models) {
#assign value of two so that which.min call won't mistake and double count predictors
temp1[j]<-2
next
}
else {
#Store t-value of newly added predictor variable to regression model
temp1[j]<-summary(lm(paste(response_name,"~.",sep=""),data=data[,c((models[models != 0]),j,dim(data)[2])]))$coefficients[i+1,4]
}
}
}
#store the predictor whose t-value is the lowest when added to the model
models[i]<-which.min(temp1)
}
print("hit this")
coefficients<-summary(lm(paste(response_name,"~.",sep=""),data=data[,c(models,dim(data)[2])]))$coefficients
names<-names(coefficients[,2])[1:p+1]
value<-coefficients[1:p+1,2]
info<-data.frame(models,names,value)
return(info)
}
character="C150_4"
dataframe=scaled_data
sample=choosing_response(scaled_data, character)
lasso=lasso_select(sample, character, 5)
colnames(lasso)=c("Lasso Relevant Variables", "Beta Coefficients")
bic=bic_select(sample, character, 5)
colnames(bic)=c("BIC Relevant Variables", "Beta Coefficients")
p_val=forward_p(sample,5)[,c(2,3)]
colnames(p_val)=c("P-Vals Relevant Variables", "Beta Coefficients")
df=cbind(lasso, bic, p_val)
save(df, "../../data/generated_data/df.RData")
library(leaps)
library(glmnet)
setwd("/Users/josephfrancia/Desktop/Fall_2016/Stats159/stat159-fall2016-project3/code/scripts")
#clean_data=read.csv("data/clean_data.csv")[,-1]
#scaled_data=read.csv("../../data/generated_data/scaled_data.csv")[,-1]
scaled_data=read.csv("../../data/generated_data/scaled_data.csv")[,-1]
choosing_response=function(dataframe, character){
response=which(colnames(dataframe)==character)
dataframe[,setdiff(93:99, response)]=NULL #getting rid of all graduation rates, except for black graduation rates
dataframe= subset(dataframe, select=c(setdiff(1:ncol(dataframe),response), response))
return(dataframe)
}
lasso_select=function(dataframe, character, n){
set.seed(0)
lasso=cv.glmnet(as.matrix(dataframe[,-which(colnames(dataframe)==character)]), dataframe[,which(colnames(dataframe)==character)])
sparse_vector=glmnet(as.matrix(dataframe[,-which(colnames(dataframe)==character)]), dataframe[,which(colnames(dataframe)==character)], lambda=lasso$lambda.1se)
relevant=which(coef(sparse_vector)!=0)[-1] #Extracting the nonzero values of our beta vector (aka, the relevant variables)... also, i removed the beta coefficient corresponding to the intercept
lasso_var=data.frame(row.names(coef(sparse_vector))[relevant], coef(sparse_vector)[relevant]) #Printing out the names of our relevant variables!
colnames(lasso_var)=c("Relevant_Variables", "Beta_Coefficients")
ordered=order(abs(lasso_var$Beta_Coefficients), decreasing=TRUE)
lasso_var=lasso_var[ordered,]
return(lasso_var[1:n,])
}
bic_select=function(dataframe, character, n){
set.seed(0)
model=summary(regsubsets(as.matrix(dataframe[,-which(colnames(dataframe)==character)]), dataframe[,which(colnames(dataframe)==character)], method="forward", nvmax=15))
bic_var=model$which[which.min(model$bic),]
relevant=which(bic_var==TRUE)[-1]
lm_obj=lm.fit(as.matrix(dataframe[, relevant-1]), dataframe[,which(colnames(dataframe)==character)])
bic_var=data.frame(rownames(data.frame(lm_obj$coefficients)),lm_obj$coefficients)
rownames(bic_var)=NULL
colnames(bic_var)=c("Relevant_Variables","Beta_Coefficients")
ordered=order(abs(bic_var$Beta_Coefficients), decreasing=TRUE)
bic_var=bic_var[ordered,]
return(bic_var[1:n,])
}
#Nick, you can do the forward selection stuff with p-values. you'll have to make a function that does that since there's no built in R thing that does that
forward_p<-function(data,p){
set.seed(0)
#data argumented must formatted such that the last column is the response variable
#p must be the number of predictor variables to use for the model, ie after addidng p variables to our model
#we stop adding predictors to our model, p must be >= 1
#break data into response and predictors,
predictors<-data[,-c(length(colnames(data)))]
response<-data[,length(colnames(data))]
response_name<-colnames(data)[dim(data)[2]]
#resultant list of all models
models<-vector(length=p)
for(i in seq(1:p)) {
temp1<-vector(length=(length(colnames(predictors))))
for (j in seq(1:(length(colnames(predictors))))){
#Initial loop to fill in temp1
if (!models[1]){
#Store t-value of regression of response variable ran on just the j'th feature of predictors
temp1[j]<-summary(lm(paste(response_name,"~."),data=data))$coefficients[i+1,4]
}
else {
#Skip if predictor is already in our model so far
if (j %in% models) {
#assign value of two so that which.min call won't mistake and double count predictors
temp1[j]<-2
next
}
else {
#Store t-value of newly added predictor variable to regression model
temp1[j]<-summary(lm(paste(response_name,"~.",sep=""),data=data[,c((models[models != 0]),j,dim(data)[2])]))$coefficients[i+1,4]
}
}
}
#store the predictor whose t-value is the lowest when added to the model
models[i]<-which.min(temp1)
}
print("hit this")
coefficients<-summary(lm(paste(response_name,"~.",sep=""),data=data[,c(models,dim(data)[2])]))$coefficients
names<-names(coefficients[,2])[1:p+1]
value<-coefficients[1:p+1,2]
info<-data.frame(models,names,value)
return(info)
}
character="C150_4"
dataframe=scaled_data
sample=choosing_response(scaled_data, character)
lasso=lasso_select(sample, character, 5)
colnames(lasso)=c("Lasso Relevant Variables", "Beta Coefficients")
bic=bic_select(sample, character, 5)
colnames(bic)=c("BIC Relevant Variables", "Beta Coefficients")
p_val=forward_p(sample,5)[,c(2,3)]
colnames(p_val)=c("P-Vals Relevant Variables", "Beta Coefficients")
df=cbind(lasso, bic, p_val)
save(df, "../../data/generated_data/df.RData")
save(df, "../../data/generated_data/df.csv")
setwd("/Users/josephfrancia/Desktop/Fall_2016/Stats159/stat159-fall2016-project3/code/scripts")
scaled_data=read.csv("data/generated_data/scaled_data.csv")[,-1]
setwd("/Users/josephfrancia/Desktop/Fall_2016/Stats159/stat159-fall2016-project3")
scaled_data=read.csv("data/generated_data/scaled_data.csv")[,-1]
choosing_response=function(dataframe, character){
response=which(colnames(dataframe)==character)
dataframe[,setdiff(93:99, response)]=NULL #getting rid of all graduation rates, except for black graduation rates
dataframe= subset(dataframe, select=c(setdiff(1:ncol(dataframe),response), response))
return(dataframe)
}
lasso_select=function(dataframe, character, n){
set.seed(0)
lasso=cv.glmnet(as.matrix(dataframe[,-which(colnames(dataframe)==character)]), dataframe[,which(colnames(dataframe)==character)])
sparse_vector=glmnet(as.matrix(dataframe[,-which(colnames(dataframe)==character)]), dataframe[,which(colnames(dataframe)==character)], lambda=lasso$lambda.1se)
relevant=which(coef(sparse_vector)!=0)[-1] #Extracting the nonzero values of our beta vector (aka, the relevant variables)... also, i removed the beta coefficient corresponding to the intercept
lasso_var=data.frame(row.names(coef(sparse_vector))[relevant], coef(sparse_vector)[relevant]) #Printing out the names of our relevant variables!
colnames(lasso_var)=c("Relevant_Variables", "Beta_Coefficients")
ordered=order(abs(lasso_var$Beta_Coefficients), decreasing=TRUE)
lasso_var=lasso_var[ordered,]
return(lasso_var[1:n,])
}
bic_select=function(dataframe, character, n){
set.seed(0)
model=summary(regsubsets(as.matrix(dataframe[,-which(colnames(dataframe)==character)]), dataframe[,which(colnames(dataframe)==character)], method="forward", nvmax=15))
bic_var=model$which[which.min(model$bic),]
relevant=which(bic_var==TRUE)[-1]
lm_obj=lm.fit(as.matrix(dataframe[, relevant-1]), dataframe[,which(colnames(dataframe)==character)])
bic_var=data.frame(rownames(data.frame(lm_obj$coefficients)),lm_obj$coefficients)
rownames(bic_var)=NULL
colnames(bic_var)=c("Relevant_Variables","Beta_Coefficients")
ordered=order(abs(bic_var$Beta_Coefficients), decreasing=TRUE)
bic_var=bic_var[ordered,]
return(bic_var[1:n,])
}
#Nick, you can do the forward selection stuff with p-values. you'll have to make a function that does that since there's no built in R thing that does that
forward_p<-function(data,p){
set.seed(0)
#data argumented must formatted such that the last column is the response variable
#p must be the number of predictor variables to use for the model, ie after addidng p variables to our model
#we stop adding predictors to our model, p must be >= 1
#break data into response and predictors,
predictors<-data[,-c(length(colnames(data)))]
response<-data[,length(colnames(data))]
response_name<-colnames(data)[dim(data)[2]]
#resultant list of all models
models<-vector(length=p)
for(i in seq(1:p)) {
temp1<-vector(length=(length(colnames(predictors))))
for (j in seq(1:(length(colnames(predictors))))){
#Initial loop to fill in temp1
if (!models[1]){
#Store t-value of regression of response variable ran on just the j'th feature of predictors
temp1[j]<-summary(lm(paste(response_name,"~."),data=data))$coefficients[i+1,4]
}
else {
#Skip if predictor is already in our model so far
if (j %in% models) {
#assign value of two so that which.min call won't mistake and double count predictors
temp1[j]<-2
next
}
else {
#Store t-value of newly added predictor variable to regression model
temp1[j]<-summary(lm(paste(response_name,"~.",sep=""),data=data[,c((models[models != 0]),j,dim(data)[2])]))$coefficients[i+1,4]
}
}
}
#store the predictor whose t-value is the lowest when added to the model
models[i]<-which.min(temp1)
}
print("hit this")
coefficients<-summary(lm(paste(response_name,"~.",sep=""),data=data[,c(models,dim(data)[2])]))$coefficients
names<-names(coefficients[,2])[1:p+1]
value<-coefficients[1:p+1,2]
info<-data.frame(models,names,value)
return(info)
}
character="C150_4"
dataframe=scaled_data
sample=choosing_response(scaled_data, character)
lasso=lasso_select(sample, character, 5)
colnames(lasso)=c("Lasso Relevant Variables", "Beta Coefficients")
bic=bic_select(sample, character, 5)
colnames(bic)=c("BIC Relevant Variables", "Beta Coefficients")
p_val=forward_p(sample,5)[,c(2,3)]
colnames(p_val)=c("P-Vals Relevant Variables", "Beta Coefficients")
df=cbind(lasso, bic, p_val)
save(df, "data/generated_data/df.RData")
?save()
save(df, file="data/generated_data/df.RData")
load(file="../../data/df.RData")
load(file="data/df.RData")
load(file="data/generated_data/df.RData")
barplot(df)
plot(df)
ui <- fluidPage(
actionButton("click", label="Generate Relevant Variables"), #Creating an action button
radioButtons("text", label=h3("Variable Selection Method"), choices=list("Lasso"="Lasso", "BIC"="BIC","P-Value"="P-Value")),
radioButtons("radio", label = h3("Select Graduation Rate of Interest"),
choices = list("Overall Graduation Rate" = "C150_4", "Graduation Rates of White People" = "C150_4_WHITE", "Graduation Rates of Black People" = "C150_4_BLACK",
"Graduation Rates of Hispanic People"="C150_4_HISP", "Graduation Rates of Asian People"="C150_4_ASIAN", "Graduation Rates of Native Americans"="C150_4_AIAN",
"Graduation Rates of Pacific Islanders"="C150_4_NHPI"),
selected = 1),
numericInput("var_num", label=h3("Number of Variables"), value=1:10),
tableOutput("variables")
)
server <- function(input, output){
observeEvent(input$click,{
df=choosing_response(scaled_data, input$radio)
if(input$text=="Lasso"){
output$variables=renderTable({lasso_select(df,input$radio,input$var_num)})
}
else if(input$text=="BIC"){
output$variables=renderTable({bic_select(df,input$radio,input$var_num)})
}
else if(input$text=="P-Value"){
output$variables=renderTable({forward_p(df, input$var_num)})
}
})
}
shinyApp(ui = ui, server = server)
library(shiny)
source("code/scripts/functions.R")
#read in file scaled_data.csv
args <- commandArgs(trailingOnly=TRUE)
scaled_data <- read.csv(args[1])[,-1]
ui <- fluidPage(
actionButton("click", label="Generate Relevant Variables"), #Creating an action button
radioButtons("text", label=h3("Variable Selection Method"), choices=list("Lasso"="Lasso", "BIC"="BIC","P-Value"="P-Value")),
radioButtons("radio", label = h3("Select Graduation Rate of Interest"),
choices = list("Overall Graduation Rate" = "C150_4", "Graduation Rates of White People" = "C150_4_WHITE", "Graduation Rates of Black People" = "C150_4_BLACK",
"Graduation Rates of Hispanic People"="C150_4_HISP", "Graduation Rates of Asian People"="C150_4_ASIAN", "Graduation Rates of Native Americans"="C150_4_AIAN",
"Graduation Rates of Pacific Islanders"="C150_4_NHPI"),
selected = 1),
numericInput("var_num", label=h3("Number of Variables"), value=1:10),
tableOutput("variables")
)
server <- function(input, output){
observeEvent(input$click,{
df=choosing_response(scaled_data, input$radio)
if(input$text=="Lasso"){
output$variables=renderTable({lasso_select(df,input$radio,input$var_num)})
}
else if(input$text=="BIC"){
output$variables=renderTable({bic_select(df,input$radio,input$var_num)})
}
else if(input$text=="P-Value"){
output$variables=renderTable({forward_p(df, input$var_num)})
}
})
}
shinyApp(ui = ui, server = server)
setwd("/Users/josephfrancia/Desktop/Fall_2016/Stats159/stat159-fall2016-project3")
